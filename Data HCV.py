# -*- coding: utf-8 -*-
"""FinalProject_BIGDATAlanjut.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MFlEXlYqtC8AHWjfxkC-L_jA83awiLiG

### ML with PySpark
+ Classify/Predict

#### Datasource
+ https://archive.ics.uci.edu/ml/datasets/HCV+data
"""

# Load our Pkgs
!pip install pyspark
from pyspark import SparkContext

# Load Pkgs
from pyspark.sql import SparkSession

spark = SparkSession.builder.master('local[2]').appName('MyApp').getOrCreate()

# Spark UI
spark

# Spark
spark = SparkSession.builder.appName("MLwithSpark").getOrCreate()

"""#### WorkFlow
+ Data Prep
+ Feature Engineering
+ Build Model
+ Evaluate

# Task
+ Predict if a patient is Hep or not based parameter
+ The data set contains laboratory values of blood donors and Hepatitis C patients and demographic values like age.
"""

# Load our dataset
df = spark.read.csv("/content/hcvdata.csv",header=True,inferSchema=True)

# Check for datatypes
# Before InferSchema=True
df.dtypes

from pyspark.sql import SparkSession
from pyspark.sql.functions import col

# Inisialisasi Spark session
spark = SparkSession.builder.appName("example").getOrCreate()

# Replace 'your_file.csv' with the actual file path
df = spark.read.csv("/content/hcvdata.csv", header=True, inferSchema=True)

# List kolom yang mengandung "NA"
columns_with_na = [col_name for col_name in df.columns if df.filter(col(col_name).isNull()).count() > 0]

# Iterasi melalui kolom dengan "NA" dan gantilah dengan mode
for col_name in columns_with_na:
    # Hitung mode
    mode_value = df.groupBy(col_name).count().orderBy(col("count").desc()).first()[col_name]

    # Gantilah nilai "NA" dengan mode
    df = df.na.fill({col_name: mode_value})

# Tampilkan DataFrame setelah menggantikan "NA" dengan mode
df.show()

# Preview Dataset
df.show()

# check for columns
print(df.columns)

# Rearrange
df = df.select('Age', 'Sex', 'ALB', 'ALP', 'ALT', 'AST', 'BIL', 'CHE', 'CHOL', 'CREA', 'GGT', 'PROT','Category')

df.show(5)

# Check for the Schema
df.printSchema()

# After InferSchema
df.dtypes

# from pyspark.sql import SparkSession
# from pyspark.sql.functions import col, sum

# # Inisialisasi sesi Spark
# spark = SparkSession.builder.appName("CheckMissingData").getOrCreate()

# # Membaca DataFrame dari sumber data (misalnya, file CSV)
# # Gantilah 'path/to/your/data.csv' dengan path file data yang sesuai
# data_path = '/content/hcvdata.csv'
# df = spark.read.csv(data_path, header=True, inferSchema=True)

# # Menampilkan schema DataFrame
# df.printSchema()

# # Menghitung jumlah data kosong untuk setiap kolom
# missing_data_counts = df.agg(*[sum(col(c).isNull().cast("int")).alias(c) for c in df.columns])

# # Menampilkan hasil
# print("Jumlah data kosong untuk setiap kolom:")
# missing_data_counts.show(truncate=False)

# # Menutup sesi Spark
# spark.stop()

# Descriptive summary
print(df.describe().show())

# Value Count
df.groupBy('Category').count().show()

df.show(5)

import pyspark.ml

dir(pyspark.ml)

# Load ML Pkgs
from pyspark.ml.feature import VectorAssembler,StringIndexer

df.show(4)

# Unique Values for Sex
df.select('Sex').distinct().show()

# Convert the string into numerical code
# label encoding
genderEncoder = StringIndexer(inputCol='Sex',outputCol='Gender').fit(df)

df = genderEncoder.transform(df)

df.show(5)

# Encoding for Category
# Label Encoding
catEncoder = StringIndexer(inputCol='Category',outputCol='Target').fit(df)
df = catEncoder.transform(df)

df.show(5)

# Get the labels
catEncoder.labels

# IndexToString
from pyspark.ml.feature import IndexToString

converter = IndexToString(inputCol='Target',outputCol='orig_cat')

converted_df = converter.transform(df)

converted_df.show()

### Feature
df.show()

print(df.columns)

df.dtypes

df2 = df.select('Age','Gender', 'ALB', 'ALP', 'ALT', 'AST', 'BIL', 'CHE', 'CHOL', 'CREA', 'GGT', 'PROT', 'Target')

df2.printSchema()

df2 = df2.toPandas().replace('NA',0).astype(float)

type(df2)

type(df)

# Convert To PySpark Dataframe
new_df = spark.createDataFrame(df2)

new_df.show()

# Check For DTYpes and Schema
new_df.printSchema()

required_features = ['Age','Gender', 'ALB', 'ALP', 'ALT', 'AST', 'BIL', 'CHE', 'CHOL', 'CREA', 'GGT', 'PROT', 'Target']

# VectorAsm
vec_assembler = VectorAssembler(inputCols=required_features,outputCol='features')

vec_df = vec_assembler.transform(new_df)

vec_df.show(5)

"""### Train,Test Split"""

train_df,test_df = vec_df.randomSplit([0.7,0.3])

train_df.count()

train_df.show(4)

# #### Model Building
# + Pyspark.ml: DataFrame
# + Pyspark.mllib: RDD /Legacy

from pyspark.ml.classification import LogisticRegression,DecisionTreeClassifier

# Logist Model
lr = LogisticRegression(featuresCol='features',labelCol='Target')

lr_model = lr.fit(train_df)

y_pred = lr_model.transform(test_df)

y_pred.show()

print(y_pred.columns)

y_pred.select('target','rawPrediction', 'probability', 'prediction').show()

"""#### Model Evaluation"""

from pyspark.ml.evaluation import MulticlassClassificationEvaluator

# How to Check For Accuracy
multi_evaluator = MulticlassClassificationEvaluator(labelCol='Target',metricName='accuracy')

multi_evaluator.evaluate(y_pred)

from pyspark.mllib.evaluation import MulticlassMetrics

lr_metric = MulticlassMetrics(y_pred['target', 'prediction'].rdd)

dir(lr_metric)

print("Accuracy",lr_metric.accuracy)

print("Precision",lr_metric.precision(1.0))
print("Recall",lr_metric.recall(1.0))
print("F1Score",lr_metric.fMeasure(1.0))

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

# Assuming y_true and y_pred are your true and predicted labels
y_true = y_pred.select('target').rdd.map(lambda x: float(x['target'])).collect()
y_pred_values = y_pred.select('prediction').rdd.map(lambda x: float(x['prediction'])).collect()

# Create a confusion matrix
cm = confusion_matrix(y_true, y_pred_values)

# Plot the heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])
plt.title('Confusion Matrix')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

dir(lr_model)

# Saving Model
lr_model.save("lr_model_30")

lr_model.write().save("mylr_model")